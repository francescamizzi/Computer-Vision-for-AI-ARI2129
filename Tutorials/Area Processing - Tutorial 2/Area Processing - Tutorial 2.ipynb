{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Processing - Tutorial 1\n",
    "\n",
    "ARI2129 - Principles of Computer Vision for AI Francesca Maria Mizzi - 118201L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to create the project is to import all the required libraries which in this case consist of OpenCv (cv2), numpy (np), matplotlib and os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images which are going to be modified are then loaded into a list. I will primarily be using the first photo \"moon-tree.jpg\" to demonstrate my work however any photos added to the images folder will also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "for x in os.listdir(\"Images\"):\n",
    "    images[x] = cv2.imread(\"Images/\" + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = cv2.imread('Images/moon-tree.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Photo\",raw)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate a sliding window, I created a class \"Window\" which will be used to define the location of the sliding window and then shift this window according to the determined stride.\n",
    "\n",
    "Certain parameters must be filled in order to generate the window:\n",
    " - image - the image where the window is going to be generated\n",
    " - scale - the size of the window (if 3 is entered then a window of 3 pixels by 3 pixels is generated)\n",
    " - stride - the amount of pixels which are going to be skipped with each shift\n",
    " \n",
    " It is to be noted that a stride or scale of 1 is not recommended since it will take a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Window:\n",
    "    \n",
    "    def __init__(self, image, scale, stride):\n",
    "        \n",
    "        self.xlim = image.shape[1]+scale\n",
    "        self.ylim = image.shape[0]+scale\n",
    "        self.top_left = (0,0)\n",
    "        self.bottom_right = (scale,scale)\n",
    "        self.prevBtmRght = scale\n",
    "        self.scale = scale\n",
    "        self.stride = (stride, stride)\n",
    "        \n",
    "        try:\n",
    "            self.channels = image.shape[2]\n",
    "        except:\n",
    "            self.channels = 1\n",
    "            \n",
    "    def pos(self):\n",
    "        \n",
    "        return self.top_left, self.bottom_right\n",
    "    \n",
    "    def newMovement(self):\n",
    "\n",
    "        self.top_left, self.bottom_right = self.newPos()\n",
    "        return self.top_left, self.bottom_right\n",
    "    \n",
    "    def newPos(self):\n",
    "        \n",
    "        if(self.bottom_right + self.stride)[0] >= (self.xlim - self.scale):\n",
    "            return (0, self.top_left[1] + self.stride[1]), (self.scale, self.bottom_right[1] + self.stride[1])\n",
    "        \n",
    "        else:\n",
    "            return (self.top_left[0] + self.stride[0], self.top_left[1]), (self.bottom_right[0] + self.stride[0], self.bottom_right[1])\n",
    "    \n",
    "    def boundaries(self, tleft = None, tright = None):\n",
    "        \n",
    "        if tleft is None:\n",
    "            tleft = self.top_left\n",
    "        if tright is None:\n",
    "            tright = self.bottom_right \n",
    "            \n",
    "        return tright[0] <= self.xlim and tright[1] <= self.ylim and tleft[0] >= 0 and tleft[1] >= 0\n",
    "    \n",
    "    def imgBoundaries(self, image):\n",
    "        \n",
    "        img = []\n",
    "        \n",
    "        for i in range(self.top_left[1], self.bottom_right[1]):\n",
    "            \n",
    "            if i >= image.shape[0]:\n",
    "                continue\n",
    "                \n",
    "            img.append(image[i][self.top_left[0]: self.bottom_right[0]])\n",
    "            \n",
    "        if self.channels == 1:\n",
    "            \n",
    "            return np.resize(np.array(img), (self.scale, self.scale))\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return np.resize(np.array(img), (self.scale, self.scale, self.channels))\n",
    "    \n",
    "    def checkY(self):\n",
    "        \n",
    "        if self.prevBtmRght == self.bottom_right[1]:\n",
    "            return False\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.prevBtmRght = self.bottom_right[1]\n",
    "            return True\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The window class is made up of 6 methods which are used to manipulate the window:\n",
    " - pos() - this method returns the current position of the window\n",
    " - newMovement() - this method shifts the window according to the new position generated by newPos()\n",
    " - newPos() - this method returns the potential position of the window after it shifts. This means either incrementing the X value or, in the case where the window has reached the edge of the photo, incrementing the Y value and resetting the X value\n",
    " - boundaries() - this method recieves locations and determines whether the given locations are within the boundaries of the image\n",
    " - imgBoundaries() - this method returns an array which contains the pixels within the window\n",
    " - checkY() - this method checks whether the value of the bottom right corner of the window has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created a function which can be used in order to generate a sliding window over any image. This function takes in 4 parameters: the image on which the sliding window is generated, the size of the window, how many pixels are to be skipped between each window and whether the user would like to see the window over the image or have it just be an internal process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, scale, stride, show):\n",
    "\n",
    "    window = Window(image, scale, stride)\n",
    "    top_left, bottom_right = window.pos()\n",
    "\n",
    "    image = cv2.rectangle(image.copy(), top_left, bottom_right, (204, 153, 255))\n",
    "    cv2.imwrite(\"Output/sliding.png\", image, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    tempright, templeft = window.newPos()\n",
    "\n",
    "    while window.boundaries(bottom_right):\n",
    "        image = cv2.rectangle(image.copy(), top_left, bottom_right, (204, 153, 255))\n",
    "        if show:\n",
    "            cv2.imshow(\"Window\", image)\n",
    "            cv2.waitKey(int(1/35*1000))\n",
    "\n",
    "        top_left, bottom_right = window.newMovement()\n",
    "        tempright = window.newPos()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window(image = raw, scale = 150, stride = 50, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Convolution on ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform convolution on the region of interest, a class must first be created for the kernel. The two properties needed in order to create the kernel is the array and the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel:\n",
    "    \n",
    "    def __init__(self, kernel, weight):\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.weight = weight\n",
    "        \n",
    "    def filterRoI(self, roi, axis = 0, channels = 1):\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        if axis == 2:\n",
    "            \n",
    "            for i in range(channels):\n",
    "                \n",
    "                if channels == 1:\n",
    "                    _filter = self.kernel * roi\n",
    "                \n",
    "                else:\n",
    "                    _filter = self.kernel * roi[:, :, i]\n",
    "                    \n",
    "                filsum = _filter.sum()\n",
    "                \n",
    "                if channels == 1:\n",
    "                    _filter = self.kernel.T * roi\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    _filter = self.kernel.T * roi[:, :, i]\n",
    "                    \n",
    "                filsum2 = _filter.sum()\n",
    "                \n",
    "                results.append((((filsum**2) + (filsum2 **2)) ** (1/2)) * self.weight)\n",
    "                \n",
    "            return np.array(results)\n",
    "        \n",
    "        else:\n",
    "            if axis == 0:\n",
    "                kernel = self.kernel \n",
    "            else:\n",
    "                self.kernel.T\n",
    "                \n",
    "            for i in range(channels):\n",
    "                \n",
    "                if channels == 1:\n",
    "                    _filter = kernel * roi\n",
    "                \n",
    "                else:\n",
    "                    _filter = kernel * roi[:, :, i]\n",
    "                    \n",
    "                results.append(_filter.sum() * self.weight)\n",
    "                \n",
    "            return np.array(results)\n",
    "        \n",
    "    def filterWhole(self, image, stride = 1, window = None, axis = 0):\n",
    "        \n",
    "        new = []\n",
    "        line = []\n",
    "        \n",
    "        if window is None:\n",
    "            \n",
    "            shift = Window(image, self.kernel.shape[0], stride)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            image = window.imgBoundaries(image)\n",
    "            shift = Window(image, self.kernel.shape[0], stride)\n",
    "            \n",
    "        top_left, _ = shift.newPos()\n",
    "        while shift.boundaries(top_left):\n",
    "            \n",
    "            roi = shift.imgBoundaries(image)\n",
    "            \n",
    "            if shift.checkY():\n",
    "                new.append(line)\n",
    "                line = []\n",
    "                \n",
    "            line.append(self.filterRoI(roi, axis, shift.channels))\n",
    "            \n",
    "            shift.newMovement()\n",
    "            top_left, _ = shift.newPos()\n",
    "            \n",
    "        return np.array(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method in the Kernel class is the filterRoI() method which has the following parameters:\n",
    " - roi - the region of interest from the image\n",
    " - axis - the axis of the operation\n",
    " - channels - the number of channels in the RoI\n",
    " \n",
    "The method is split up into 2 parts, determined by the axis.\n",
    "\n",
    "**If the axis is 2**, the method multiplies the pixels of the region of interest in the channel with those of the kernel, then adds them together. It then multiplies the pixels of the RoI in the channel with those in the transpose of the kernal, then adds them together. The magnitude of the added values is found by squaring the values, adding them together and finding the square root. This answer is then multiplied by the weight of the kernel and added to the list \"results\". This is done for all the channels. The list of results is converted to an array and returned to the user.\n",
    "\n",
    "**If the axis is not 2**, the method multiplies the pixels in the channel with those of the kernel then adds them together. It then multiplies this resilt with the weight of the kernel and adds it to the \"results\" list. This is done for all the channels. The list of results is converted to an array and returned to the user.\n",
    "\n",
    "It is important that the region of interest and the kernel have the same shape or the method will not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other method in the class is the filterWhole() method. This method has 4 parameters: the image which needs to be filtered, the amount of pixels which need to be skipped (stride), if the filter is to be carried out on a region of interest, a window is required and the axis of operation.\n",
    "\n",
    "A check is carried out to see whether the filter is applied to a window or to the whole image. If a window is defined, the pixels within this window are assigned as the image using the imgBoundaries() method defined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class was created for the Sobel kernel used to carry out the convolution, storing the array and the weight of the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sobel:\n",
    "    def __init__(self, weight):\n",
    "        self.kernel = Kernel(np.array([[-1, 0, 1],\n",
    "                                       [-2, 0, 2],\n",
    "                                       [-1, 0, 1]]),\n",
    "                             weight)\n",
    "\n",
    "    def filter_s(self, image, stride=1, window=None, axis=2):\n",
    "        return self.kernel.filterWhole(image, stride, window, axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the sobel kernel is initialized, a region of interest is extracted in a 900x900 pixel square. This region of interest is then passed through the sobel filter and presented to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sobel = Sobel(1)\n",
    "\n",
    "wind = Window(raw, 500, 1)\n",
    "roi = wind.imgBoundaries(raw)\n",
    "\n",
    "sobel_filtered = sobel.filter_s(image = raw, window = wind, axis = 2)\n",
    "\n",
    "cv2.imshow(\"Original ROI\",roi)\n",
    "cv2.imshow(\"Sobel Filter\", sobel_filtered)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Convolution on the whole image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtering of the whole image is done simply by passing the image through the filter, as done prior, but excluding the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_sobel_filtered = sobel.filter_s(image = raw, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original Photo\",raw)\n",
    "cv2.imshow(\"Sobel Filter\", whole_sobel_filtered)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Different Convolution Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter the images through gaussian and bilinear kernels, I created two seperate classes for the kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bilinear:\n",
    "    \n",
    "    def __init__(self, weight):\n",
    "        \n",
    "        self.kernel = Kernel(np.array([[1, 2, 1],\n",
    "                                       [2, 4, 2],\n",
    "                                       [1, 2, 1]]), weight)\n",
    "        \n",
    "    def filter_bil(self, image, pace = 1, window = None, axis = 0):\n",
    "        return self.kernel.FilterImage(image, pace, window, axis)\n",
    "\n",
    "class Gaussian:\n",
    "    \n",
    "    def __init__(self, size, weight):\n",
    "        \n",
    "        gauss = size // 2\n",
    "        \n",
    "        x = np.arange(0, size, 1, float)\n",
    "        \n",
    "        y = x[:, np.newaxis]\n",
    "        \n",
    "        tempx = tempy = size // 2\n",
    "        self.kernel = Kernel(np.exp(-4 * np.log(2) * ((x - tempx) ** 2 + (y - tempy) ** 2) / gauss ** 2), weight)\n",
    "        \n",
    "    def filter_gaus(self, image, pace = 1, window = None, axis = 0):\n",
    "        return self.kernel.FilterImage(image, pace, window, axis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initialized the two kernels, defined their weights and added all three filters to a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear = Bilinear(1/8)\n",
    "gaussian = Gaussian(5, 1/4)\n",
    "\n",
    "filters = {\"Sobel\": sobel,\n",
    "          \"Bilinear\": bilinear,\n",
    "           \"Gaussian\": gaussian}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then passed all my images through the filters in order to have a good representation as to the effects of the filters. \n",
    "\n",
    "It is to be noted that the x and y values for the sobel kernel were processed seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-d9db6180baa2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Sobel\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0mfilteredX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphoto\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Filters\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mphoto\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"FILTERED_SOBELX.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilteredX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMWRITE_PNG_COMPRESSION\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mfilteredY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-0a6efb898982>\u001b[0m in \u001b[0;36mfilter_s\u001b[1;34m(self, image, stride, window, axis)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfilter_s\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterWhole\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-da3b9c5e5ff6>\u001b[0m in \u001b[0;36mfilterWhole\u001b[1;34m(self, image, stride, window, axis)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mroi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgBoundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-6a713478d1c1>\u001b[0m in \u001b[0;36mimgBoundaries\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheckY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(a, new_shape)\u001b[0m\n\u001b[0;32m   1415\u001b[0m         \u001b[0mextra\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNa\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mextra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1417\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_copies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1418\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mextra\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mextra\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for photo in images:\n",
    "    for entry in filters:\n",
    "        if entry == \"Sobel\":\n",
    "\n",
    "            filteredX = filters[entry].filter_s(image=images[photo], axis = 0)\n",
    "            cv2.imwrite(\"Filters\"+ photo +\"FILTERED_SOBELX.png\", filteredX, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "            filteredY = filters[entry].filter_s(image=images[image], axis = 1)\n",
    "            cv2.imwrite(\"Filters\"+ photo +\"FILTERED_SOBELY.png\", filteredY, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "        elif entry == \"Bilinear\":\n",
    "            filteredB = filters[entry].filter_bil(image=images[photo])\n",
    "            cv2.imwrite(\"Filters\"+ photo +\"FILTERED_BILINEAR.png\", filteredB, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "        else:\n",
    "            filteredG = filters[entry].filter_gaus(image=images[photo])\n",
    "            cv2.imwrite(\"Filters\"+ photo +\"FILTERED_GAUSSIAN.png\", filteredG, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
