{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Processing - Tutorial 1\n",
    "\n",
    "ARI2129 - Principles of Computer Vision for AI Francesca Maria Mizzi - 118201L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to create the project is to import all the required libraries which in this case consist of OpenCv (cv2), numpy (np), matplotlib and os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images which are going to be modified are then loaded into a list. I will primarily be using the first photo \"moon-tree.jpg\" to demonstrate my work however any photos added to the images folder will also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}\n",
    "for x in os.listdir(\"Images\"):\n",
    "    images[x] = cv2.imread(\"Images/\" + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = cv2.imread('Images/moon-tree.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Photo\",raw)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Sliding Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate a sliding window, I created a class \"Window\" which will be used to define the location of the sliding window and then shift this window according to the determined stride.\n",
    "\n",
    "Certain parameters must be filled in order to generate the window:\n",
    " - image - the image where the window is going to be generated\n",
    " - scale - the size of the window (if 3 is entered then a window of 3 pixels by 3 pixels is generated)\n",
    " - stride - the amount of pixels which are going to be skipped with each shift\n",
    " \n",
    " It is to be noted that a stride or scale of 1 is not recommended since it will take a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Window:\n",
    "    \n",
    "    def __init__(self, image, scale, stride):\n",
    "        \n",
    "        self.xlim = image.shape[1]+scale\n",
    "        self.ylim = image.shape[0]+scale\n",
    "        self.top_left = (0,0)\n",
    "        self.bottom_right = (scale,scale)\n",
    "        self.prevBtmRght = scale\n",
    "        self.scale = scale\n",
    "        self.stride = (stride, stride)\n",
    "        \n",
    "        try:\n",
    "            self.channels = image.shape[2]\n",
    "        except:\n",
    "            self.channels = 1\n",
    "            \n",
    "    def pos(self):\n",
    "        \n",
    "        return self.top_left, self.bottom_right\n",
    "    \n",
    "    def newMovement(self):\n",
    "\n",
    "        self.top_left, self.bottom_right = self.newPos()\n",
    "        return self.top_left, self.bottom_right\n",
    "    \n",
    "    def newPos(self):\n",
    "        \n",
    "        if(self.bottom_right + self.stride)[0] >= (self.xlim - self.scale):\n",
    "            return (0, self.top_left[1] + self.stride[1]), (self.scale, self.bottom_right[1] + self.stride[1])\n",
    "        \n",
    "        else:\n",
    "            return (self.top_left[0] + self.stride[0], self.top_left[1]), (self.bottom_right[0] + self.stride[0], self.bottom_right[1])\n",
    "    \n",
    "    def boundaries(self, tleft = None, tright = None):\n",
    "        \n",
    "        if tleft is None:\n",
    "            tleft = self.top_left\n",
    "        if tright is None:\n",
    "            tright = self.bottom_right \n",
    "            \n",
    "        return tright[0] <= self.xlim and tright[1] <= self.ylim and tleft[0] >= 0 and tleft[1] >= 0\n",
    "    \n",
    "    def imgBoundaries(self, image):\n",
    "        \n",
    "        img = []\n",
    "        \n",
    "        for i in range(self.top_left[1], self.bottom_right[1]):\n",
    "            \n",
    "            if i >= image.shape[0]:\n",
    "                continue\n",
    "                \n",
    "            img.append(image[i][self.top_left[0]: self.bottom_right[0]])\n",
    "            \n",
    "        if self.channels == 1:\n",
    "            \n",
    "            return np.resize(np.array(img), (self.scale, self.scale))\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return np.resize(np.array(img), (self.scale, self.scale, self.channels))\n",
    "    \n",
    "    def checkY(self):\n",
    "        \n",
    "        if self.prevBtmRght == self.bottom_right[1]:\n",
    "            return False\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.prevBtmRght = self.bottom_right[1]\n",
    "            return True\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The window class is made up of 6 methods which are used to manipulate the window:\n",
    " - pos() - this method returns the current position of the window\n",
    " - newMovement() - this method shifts the window according to the new position generated by newPos()\n",
    " - newPos() - this method returns the potential position of the window after it shifts. This means either incrementing the X value or, in the case where the window has reached the edge of the photo, incrementing the Y value and resetting the X value\n",
    " - boundaries() - this method recieves locations and determines whether the given locations are within the boundaries of the image\n",
    " - imgBoundaries() - this method returns an array which contains the pixels within the window\n",
    " - checkY() - this method checks whether the value of the bottom right corner of the window has changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then created a function which can be used in order to generate a sliding window over any image. This function takes in 4 parameters: the image on which the sliding window is generated, the size of the window, how many pixels are to be skipped between each window and whether the user would like to see the window over the image or have it just be an internal process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, scale, stride, show):\n",
    "\n",
    "    window = Window(image, scale, stride)\n",
    "    top_left, bottom_right = window.pos()\n",
    "\n",
    "    image = cv2.rectangle(image.copy(), top_left, bottom_right, (204, 153, 255))\n",
    "    cv2.imwrite(\"Output/sliding.png\", image, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "    tempright, templeft = window.newPos()\n",
    "\n",
    "    while window.boundaries(bottom_right):\n",
    "        image = cv2.rectangle(image.copy(), top_left, bottom_right, (204, 153, 255))\n",
    "        if show:\n",
    "            cv2.imshow(\"Window\", image)\n",
    "            cv2.waitKey(int(1/35*1000))\n",
    "\n",
    "        top_left, bottom_right = window.newMovement()\n",
    "        tempright = window.newPos()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window(image = raw, scale = 150, stride = 50, show = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Convolution on ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform convolution on the region of interest, a class must first be created for the kernel. The two properties needed in order to create the kernel is the array and the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel:\n",
    "    \n",
    "    def __init__(self, kernel, weight):\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.weight = weight\n",
    "        \n",
    "    def filterRoI(self, roi, axis = 0, channels = 1):\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        if axis == 2:\n",
    "            \n",
    "            for i in range(channels):\n",
    "                \n",
    "                if channels == 1:\n",
    "                    _filter = self.kernel * roi\n",
    "                \n",
    "                else:\n",
    "                    _filter = self.kernel * roi[:, :, i]\n",
    "                    \n",
    "                filter_sum = _filter.sum()\n",
    "                \n",
    "                if channels == 1:\n",
    "                    _filter = self.kernel.T * roi\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    _filter = self.kernel.T * roi[:, :, i]\n",
    "                    \n",
    "                filter_sum2 = _filter.sum()\n",
    "                \n",
    "                results.append((((filter_sum**2) + (filter_sum2 **2)) ** (1/2)) * self.weight)\n",
    "                \n",
    "            return np.array(results)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            kernel = self.kernel if axis == 0 else self.kernel.T\n",
    "            \n",
    "            for i in range(channels):\n",
    "                \n",
    "                if channels == 1:\n",
    "                    _filter = kernel * roi\n",
    "                    \n",
    "                else:\n",
    "                    _filter = kernel * roi[:, :, i]\n",
    "                    \n",
    "                results.append(_filter.sum() * self.weight)\n",
    "                \n",
    "            return np.array(results)\n",
    "        \n",
    "    def filterWhole(self, image, stride, window = None, axis = 0):\n",
    "        \n",
    "        new = []\n",
    "        line = []\n",
    "        \n",
    "        if window is None:\n",
    "            \n",
    "            shift = Window(image, self.kernel.shape[0], stride)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            image = window.imgBoundaries(image)\n",
    "            shift = Window(image, self.kernel.shape[0], stride)\n",
    "            \n",
    "        top_left, _ = shift.newPos()\n",
    "        while shift.boundaries(top_left):\n",
    "            \n",
    "            roi = shift.imgBoundaries(image)\n",
    "            \n",
    "            if shift.checkY():\n",
    "                new.append(line)\n",
    "                line = []\n",
    "                \n",
    "            line.append(self.filterRoI(roi, axis, shift.channels))\n",
    "            \n",
    "            shift.newMovement()\n",
    "            top_left, _ = shift.newPos()\n",
    "            \n",
    "        return np.array(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method in the Kernel class is the filterRoI() method which has the following parameters:\n",
    " - roi - the region of interest from the image\n",
    " - axis - the axis of the operation\n",
    " - channels - the number of channels in the RoI\n",
    " \n",
    "The method is split up into 2 parts, determined by the axis.\n",
    "\n",
    "**If the axis is 2**, the method multiplies the pixels of the region of interest in the channel with those of the kernel, then adds them together. It then multiplies the pixels of the RoI in the channel with those in the transpose of the kernal, then adds them together. The magnitude of the added values is found by squaring the values, adding them together and finding the square root. This answer is then multiplied by the weight of the kernel and added to the list \"results\". This is done for all the channels. The list of results is converted to an array and returned to the user.\n",
    "\n",
    "**If the axis is not 2**, the method multiplies the pixels in the channel with those of the kernel then adds them together. It then multiplies this resilt with the weight of the kernel and adds it to the \"results\" list. This is done for all the channels. The list of results is converted to an array and returned to the user.\n",
    "\n",
    "It is important that the region of interest and the kernel have the same shape or the method will not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other method in the class is the filterWhole() method. This method has 4 parameters: the image which needs to be filtered, the amount of pixels which need to be skipped (stride), if the filter is to be carried out on a region of interest, a window is required and the axis of operation.\n",
    "\n",
    "A check is carried out to see whether the filter is applied to a window or to the whole image. If a window is defined, the pixels within this window are assigned as the image using the imgBoundaries() method defined earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class was created for the Sobel kernel used to carry out the convolution, storing the array and the weight of the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sobel:\n",
    "    def __init__(self, weight):\n",
    "        self.kernel = Kernel(np.array([[-1, 0, 1],\n",
    "                                       [-2, 0, 2],\n",
    "                                       [-1, 0, 1]]),\n",
    "                             weight)\n",
    "\n",
    "    def filter_s(self, image, stride=10, window=None, axis=2):\n",
    "        return self.kernel.filterWhole(image, stride, window, axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the sobel kernel is initialized, a region of interest is extracted in a 900x900 pixel square. This region of interest is then passed through the sobel filter and presented to the user.\n",
    "\n",
    "Since filtering the images takes some time, I chose to store the images in a folder in order to facilitate viewing the resutls of the filter without running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel = Sobel(1)\n",
    "\n",
    "for photo in images:\n",
    "    wind = Window(images[photo], 600, 1)\n",
    "    roi = wind.imgBoundaries(images[photo])\n",
    "\n",
    "    sobel_filtered = sobel.filter_s(image = images[photo], window = wind, axis = 2)\n",
    "\n",
    "    cv2.imwrite(\"Filters/SobelRoI/\"+ photo +\"_originalRoI.png\", roi, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "    cv2.imwrite(\"Filters/SobelRoI/\"+ photo +\"_filteredRoI.png\", sobel_filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Filters/SobelRoI/city-night.jpg_originalRoI.png' width = \"300\">\n",
    "<img src = 'Filters/SobelRoI/city-night.jpg_filteredRoI.png' width = \"300\">\n",
    "\n",
    "<img src = 'Filters/SobelRoI/mountain.jpg_originalRoI.png' width = \"300\">\n",
    "<img src = 'Filters/SobelRoI/mountain.jpg_filteredRoI.png' width = \"300\">\n",
    "\n",
    "<img src = 'Filters/SobelRoI/moon-tree.jpg_originalRoI.png' width = \"300\">\n",
    "<img src = 'Filters/SobelRoI/moon-tree.jpg_filteredRoI.png' width = \"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the results, 2 out of 3 of the photos resulted in a very dark RoI after being filtered. This is likely due to the fact that the RoI selected from the original photo has no real subject.\n",
    "\n",
    "This is however not the case with moon-tree.jpg where the filtered result can easily be recognized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Convolution on the whole image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtering of the whole image is done simply by passing the image through the filter, as done prior, but excluding the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_sobel_filtered = sobel.filter_s(image = raw, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"Filters/\"+ photo +\"_whole_sobel_filtered.png\", whole_sobel_filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Filters/moon-tree.jpg_whole_sobel_filtered.png' width = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the result, the features of the image after the sobel filter are very clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Different Convolution Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter the images through gaussian and bilinear kernels, I created two seperate classes for the kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bilinear:\n",
    "    \n",
    "    def __init__(self, weight):\n",
    "        \n",
    "        self.kernel = Kernel(np.array([[1, 2, 1],\n",
    "                                       [2, 4, 2],\n",
    "                                       [1, 2, 1]]), weight)\n",
    "        \n",
    "    def filter_bil(self, image, stride = 10, window = None, axis = 0):\n",
    "        return self.kernel.filterWhole(image, stride, window, axis)\n",
    "\n",
    "class Gaussian:\n",
    "    \n",
    "    def __init__(self, size, weight):\n",
    "        \n",
    "        gauss = size // 2\n",
    "        \n",
    "        x = np.arange(0, size, 1, float)\n",
    "        \n",
    "        y = x[:, np.newaxis]\n",
    "        \n",
    "        tempx = tempy = size // 2\n",
    "        self.kernel = Kernel(np.exp(-4 * np.log(2) * ((x - tempx) ** 2 + (y - tempy) ** 2) / gauss ** 2), weight)\n",
    "        \n",
    "    def filter_gaus(self, image, stride = 10, window = None, axis = 0):\n",
    "        return self.kernel.filterWhole(image, stride, window, axis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I initialized the two kernels, defined their weights and added all three filters to a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilinear = Bilinear(1/8)\n",
    "gaussian = Gaussian(5, 1/4)\n",
    "\n",
    "filters = {\"Sobel\": sobel,\n",
    "          \"Bilinear\": bilinear,\n",
    "           \"Gaussian\": gaussian}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then passed all my images through the filters in order to have a good representation as to the effects of the filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Kindly note that for some reason, this execution of this cell takes a very long time. \n",
    "# It does however work in the end, I promise.\n",
    "for photo in images:\n",
    "    for entry in filters:\n",
    "        if entry == \"Sobel\":\n",
    "            filtered = filters[entry].filter_s(image=images[photo], axis = 2)\n",
    "            cv2.imwrite(\"Filters/Sobel/\"+ photo +\"FILTERED_SOBEL.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "        elif entry == \"Bilinear\":\n",
    "            filtered = filters[entry].filter_bil(image=images[photo])\n",
    "            cv2.imwrite(\"Filters/Bilinear/\"+ photo +\"FILTERED_BILINEAR.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])\n",
    "\n",
    "        else:\n",
    "            filtered = filters[entry].filter_gaus(image=images[photo])\n",
    "            cv2.imwrite(\"Filters/Gaussian/\"+ photo +\"FILTERED_GAUSSIAN.png\", filtered, [cv2.IMWRITE_PNG_COMPRESSION, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the results, all of the filters where effective on the photos.\n",
    "\n",
    "#### Sobel\n",
    "\n",
    "In all three cases, the sobel filter very clearly showed the features of the image. It is to be noted that in the city-night.jpg photo, a white line appeared in the sky wich seems to correspond with the clouds location in the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Filters/Sobel/city-night.jpgFILTERED_SOBEL.png' width = \"300\">\n",
    "<img src = 'Filters/Sobel/mountain.jpgFILTERED_SOBEL.png' width = \"300\">\n",
    "<img src = 'Filters/Sobel/moon-tree.jpgFILTERED_SOBEL.png' width = \"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bilinear\n",
    "\n",
    "While all three photos have been brightened, the effects of the filter are very clearly seen in mountain.jpg. We can see how the source of light (the sun) has almost been entirely washed out with white. This is different than in city-night.jpg where at first, the filter does not seem to have had an effect however, once the filtered image is compared to the original, the differnce is easily noticed, especially in the details in the sky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Filters/Bilinear/city-night.jpgFILTERED_BILINEAR.png' width = \"300\">\n",
    "<img src = 'Filters/Bilinear/mountain.jpgFILTERED_BILINEAR.png' width = \"300\">\n",
    "<img src = 'Filters/Bilinear/moon-tree.jpgFILTERED_BILINEAR.png' width = \"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian\n",
    "\n",
    "While initially looking at the first two photos, I didn't see a big difference after the Gaussian filter but I then saw the moon-tree.jpg photo and immediatley knew that the filter had been successfully applied. The tree branches in the photo are very blurry compared to those in the original photo as well as the outline of the moon.\n",
    "This implies that the filter is most effective when there is a central focus to the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Filters/Gaussian/city-night.jpgFILTERED_GAUSSIAN.png' width = \"300\">\n",
    "<img src = 'Filters/Gaussian/mountain.jpgFILTERED_GAUSSIAN.png' width = \"300\">\n",
    "<img src = 'Filters/Gaussian/moon-tree.jpgFILTERED_GAUSSIAN.png' width = \"300\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
